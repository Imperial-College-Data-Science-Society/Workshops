{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Inference and Learning in the Big Data Regime\n",
    "\n",
    "Many real-world modelling solutions require fitting models with large numbers of data-points and parameters, which is made convenient recently through software implementing automatic differentiation, but also require uncertainty quantification. Variational inference is a generic family of tools that reformulates (Bayesian) model inference into an optimisation problem, thereby making use of modern software tools but also having the ability to give model uncertainty. This talk will motivate how variational inference works and what the state-of-the-art methods are. We will also accompany the theory with implementations on some simple probabilistic models, such as variational autoencoders (VAE). If time-permitting, we will briefly talk about some of the recent frontiers of variational inference, namely normalising flows and Stein Variational Gradient Descent.\n",
    "\n",
    " \n",
    "\n",
    "üíª Content covered:\n",
    "\n",
    "Current inference methods: maximum likelihood and Markov chain Monte Carlo\n",
    "\n",
    "Information theory and KL divergence\n",
    "\n",
    "Mean field variational inference\n",
    "\n",
    "Bayesian linear regression\n",
    "\n",
    "Monte Carlo variational inference (MCVI), reparameterisation trick and law of the unconscious statistician (LOTUS)\n",
    "\n",
    "Example software implementations: VAE\n",
    "\n",
    "üëæ This lecture will be held online on Microsoft Teams.\n",
    "\n",
    "üî¥The event will be recorded and will be publicly available.\n",
    "\n",
    "üéâ Attendance is FREE for members! Whether you are a student at Imperial College or not, sign up to be a member at www.icdss.club/joinus\n",
    "\n",
    "‚≠êÔ∏è We encourage participants of this workshop to have looked at our previous sessions on YouTube. Prerequisites: basic understanding of Bayesian statistics\n",
    "\n",
    "üìñ A schedule of our lecture series is currently available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "- Variational Inference: A Review for Statisticians: https://www.tandfonline.com/doi/full/10.1080/01621459.2017.1285773\n",
    "- Auto-Encoding Variational Bayes: https://arxiv.org/pdf/1312.6114.pdf\n",
    "- http://yingzhenli.net/home/en/approximateinference\n",
    "- https://github.com/ethanluoyc/pytorch-vae\n",
    "\n",
    "Consider crop yields $y$ and we have a likelihood $p(y|z)$ where $z$ are latent parameters. Suppose $z$ has some prior distribution $p(z)$, then the posterior distribution is\n",
    "$$\n",
    "p(z|y) \\propto p(y|z)p(z) := \\tilde{p}(z|y).\n",
    "$$\n",
    "\n",
    "We then want to be able to compute quantities $\\mathbb{E}_{z\\sim p(z|y)}[h(Z)]$, for certain functions $h$ e.g. $h(z)=z$ for the posterior mean of $Z$.\n",
    "\n",
    "We could compute $p(z|y$) analytically if we have nice priors (conjugate priors), but this is usually not the case for most models e.g. Autoencoders with latent parameters or certain Gaussian mixture models. \n",
    "\n",
    "Markov chain Monte Carlo (MCMC) allows us to obtain samples from $z\\sim p(z|y)$ using samplers (e.g. Hamiltonian Monte Carlo (HMC) or Metropolis-Hastings), but it could be very expensive and prohibits it from being used for the big data setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variational Inference\n",
    "\n",
    "Variational Inference (VI)/Variational Bayes/Variational Approximation turns this problem into an optimisation problem. We now seek $q(z)$ in a space of functions $\\mathcal{Q}$, instead of computing the exact $p(z|y)$, in which\n",
    "\n",
    "$$KL(q(z) || p(z|y)) = \\int \\log\\frac{q(z)}{p(z|y)} q(z) dq$$\n",
    "\n",
    "is minimised. This KL denotes the KL-divergence, which is a divergence measure that looks at how close 2 distributions are to one-another. It is:\n",
    "\n",
    "- Non-negative\n",
    "- Is equal to 0 if and only if $q(z) = p(z|y)$\n",
    "- Note: $KL(q(z)||p(z|y)) \\neq KL(p(z|y) || q(z))$. Minimising $KL(p(z|y) || q(z))$ is the objective of Expectation Propagation, which is another method for approximating posterior distributions.\n",
    "\n",
    "Note that maximum likelihood estimation (MLE) is done by maximising the log-likelihood, which is the same as minimising the KL divergence:\n",
    "\n",
    "$$\n",
    "\\text{argmin}_{\\theta} KL(\\hat{p}(y|\\theta^*) || p(y|\\theta)) = \\text{argmin}_{\\theta} \\frac{1}{n}\\sum_{i=1}^n \\log \\frac{p(y_i|\\hat{\\theta})}{p(y_i|\\theta)} = \\text{argmin}_{\\theta} \\frac{1}{n}\\sum_{i=1}^n \\log \\frac{1}{p(y_i|\\theta)} = \\text{argmax}_{\\theta} \\frac{1}{n}\\sum_{i=1}^n \\log p(y_i|\\theta).\n",
    "$$\n",
    "\n",
    "**Evidence Lower-Bound**\n",
    "\n",
    "Suppose I pose a family of posteriors $q(z)$, then\n",
    "\n",
    "\\begin{align*}\n",
    "KL(q(z) || p(z|y)) = \\int \\log\\frac{q(z)}{p(z|y)} q(z) dq &= \\mathbb{E}_{z\\sim q(z)}[\\log q(z)] - \\mathbb{E}_{z\\sim q(z)}[\\log p(z|y)] \\\\\n",
    "&= \\mathbb{E}_{z\\sim q(z)}[\\log q(z)] - \\mathbb{E}_{z\\sim q(z)}[\\log p(z,y)] + \\log p(y) \\\\\n",
    "&= \\mathbb{E}_{z\\sim q(z)}[\\log q(z)] - \\mathbb{E}_{z\\sim q(z)}[\\log p(y|z)] - \\mathbb{E}_{z\\sim q(z)}[p(z)]  + \\log p(y) \\\\\n",
    "&=\\log p(y) + \\mathbb{E}_{z\\sim q(z)}[\\log \\frac{q(z)}{p(z)}] - \\mathbb{E}_{z\\sim q(z)}[\\log p(y|z)]  \\\\\n",
    "&= \\log p(y) + KL(q(z) || p(z)) - \\mathbb{E}_{z\\sim q(z)}[\\log p(y|z)].\n",
    "\\end{align*}\n",
    "\n",
    "Since the left term is positive and $\\log p(y)$ is fixed, it is sufficient to minimise:\n",
    "\n",
    "$$\n",
    "KL(q(z) || p(z)) - \\mathbb{E}_{z\\sim q(z)}[\\log p(y|z)].\n",
    "$$\n",
    "\n",
    "The evidence lower-bound is $ELBO(q) = \\mathbb{E}_{z\\sim q(z)}[\\log p(y|z)] - KL(q(z) || p(z))$, which is maximised.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean-Field Variational Inference\n",
    "\n",
    "As fancy as it sounds, it just means specifying a family of posteriors $\\mathcal{Q}$ such that \n",
    "\n",
    "$$\n",
    "q(z) = \\prod_{j=1}^m q_j(z_j),\n",
    "$$\n",
    "where $m$ is the number of parameters.\n",
    "\n",
    "**Coordinate Ascent Variational Inference (CAVI)**\n",
    "Blei et al. (2017)\n",
    "![](cavi.png)\n",
    "\n",
    "Let's look at an example (Li (2021)):\n",
    "$$\n",
    "y|x \\sim \\mathcal{N}(y; x^\\intercal\\theta, \\sigma^2),\\qquad \\theta\\sim\\mathcal{N}(\\theta; \\mu_0, \\Gamma_0^{-1}).\n",
    "$$\n",
    "This has an analytical solution\n",
    "$$\n",
    "p(\\theta|\\mathcal{D}) = \\mathcal{N}(\\theta; \\mu,\\Gamma^{-1})\n",
    "$$\n",
    "with\n",
    "\\begin{align*}\n",
    "\\Gamma &= \\Gamma_0 + \\frac{1}{\\sigma^2}X^\\intercal X \\\\\n",
    "\\mu &= \\frac{1}{\\sigma^2}(X^\\intercal X + \\Gamma_0)^{-1}X^Ty,\n",
    "\\end{align*}\n",
    "\n",
    "where $X=(x_1,\\ldots,x_n)^\\intercal$ and $y=(y_1,\\ldots,y_n)^\\intercal$. **Let's try CAVI**:\n",
    "\n",
    "\\begin{align*}\n",
    "\\log q_1(\\theta_1) =& \\int q_2(\\theta_2) \\log \\tilde{p}(\\theta_1, \\theta_2) d\\theta_2\\\\\n",
    "=& \\int -\\frac{1}{2}\\left[(\\theta_1-\\mu_1)^2\\Gamma_{11} + 2(\\theta_1-\\mu_1)\\Gamma_{12}(\\theta_2-\\mu_2) \\right]q_2(\\theta_2) d\\theta_2 + const \\\\\n",
    "=& -\\frac{1}{2}\\left[(\\theta_1-\\mu_1)^2\\Gamma_{11} + 2(\\theta_1-\\mu_1)\\Gamma_{12}(\\mathbb{E}_{\\theta_2\\sim q_2}[\\theta_2]-\\mu_2) \\right] + const,\n",
    "\\end{align*}\n",
    "which is Gaussian with mean and variance\n",
    "$$\n",
    "\\tilde{\\mu}_1 = \\mu_1 - \\Gamma_{11}^{-1}\\Gamma_{12}(\\mathbb{E}_{q_2}[\\theta_2] - \\mu_2),\\qquad \\tilde{\\gamma}_2^{-1} = \\Gamma_{11}.\n",
    "$$\n",
    "Similarly, you can obtain a similar expression for $q_2(\\theta_2)$. For CAVI to convergence, it can be shown that $(\\tilde{\\mu}_1, \\tilde{\\mu}_2)^\\intercal = \\mu$, giving\n",
    "\n",
    "$$\n",
    "\\tilde{\\mu}_1 = \\mu_1, \\qquad \\tilde{\\mu}_2 = \\mu_2.\n",
    "$$\n",
    "\n",
    "In this case, CAVI gives a Gaussian posteriors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monte Carlo Variational Inference (MCVI)\n",
    "\n",
    "For big data situations, the variational expectation term can be (1) very expensive and (2) is not available in closed form. We can also add some more complexity to the posterior instead of just having a mean-field approximation. Recall the bound:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(q; p) = KL(q(z) || p(z)) - \\mathbb{E}_{z\\sim q(z)}[\\log p(y|z)].\n",
    "$$\n",
    "\n",
    "MCVI calculates the variational expectation using Monte Carlo integration\n",
    "$$\n",
    "\\mathbb{E}_{z\\sim q(z)}[\\log p(y_i|z)] \\approx \\frac{1}{M}\\sum_{j=1}^M \\log p(y_i|z^j),\\qquad z^j\\sim q(z).\n",
    "$$\n",
    "Even better, we can calculate this using mini-batches:\n",
    "$$\n",
    "\\sum_{i=1}^n\\mathbb{E}_{z\\sim q(z)}[\\log p(y_i|z)]  = \\mathbb{E}_{S\\sim \\{1,\\ldots,n\\}}\\left[\\frac{n}{|S|}\\sum_{i\\in S} \\mathbb{E}_q[\\log p(y_i|z)] \\right],\n",
    "$$\n",
    "\n",
    "where the inner expectation can be calculated as before. Now, to minimise $\\mathcal{L}(q; p)$, we differentiate with respect to the parameters, let's call it $\\theta$. Therefore, we need\n",
    "\n",
    "\\begin{align*}\n",
    "\\nabla_\\theta \\mathcal{L}(q; p) =& \\nabla_\\theta\\left[KL(q(z) || p(z)) - \\mathbb{E}_{z\\sim q(z)}[\\log p(y|z)] \\right] \\\\\n",
    "=& \\nabla_\\theta \\left[ \\frac{1}{M}\\sum_{j=1}^M \\log\\frac{q(z^j)}{p(z^j)} \\right] - \\nabla_\\theta\\left[\\mathbb{E}_{S\\sim \\{1,\\ldots,n\\}}\\left[\\frac{n}{|S|}\\sum_{i\\in S} \\frac{1}{M}\\sum_{j=1}^M \\log p(y_i|z^j)\\right] \\right],\n",
    "\\end{align*}\n",
    "\n",
    "where $z^j\\sim q(z)$. We can get rid of the expectation with respect to the mini-batches and get a nice approximation for the bound for each batch $S$.\n",
    "\n",
    "**Reparameterisation Trick/Law of the Unconcious Statistician (LOTUS)**\n",
    "LOTUS basically refers to the identity:\n",
    "\n",
    "$$\n",
    "E_X[f(X)] = \\int f(x) p(x) dx = \\int f(g(\\epsilon)) p(\\epsilon) dx = E_\\epsilon[f(g(\\epsilon))]\n",
    "$$\n",
    "\n",
    "for $x=g(\\epsilon)$, via the inverse function theorem and the change of variable theorem. The reparameterisation trick thus makes it easier to compute the bound by allowing us to sample from a simpler distribution $p(\\epsilon)$ to get $q(z)$:\n",
    "\n",
    "\\begin{align*}\n",
    "\\nabla_\\theta \\mathcal{L}(q; p) =& \\nabla_\\theta\\left[KL(q(z) || p(z)) - \\mathbb{E}_{z\\sim q(z)}[\\log p(y|z)] \\right] \\\\\n",
    "=& \\nabla_\\theta\\left[KL(q(z) || p(z)) - \\mathbb{E}_{\\epsilon}[\\log p(y|g_\\theta(\\epsilon))] \\right]\\\\\n",
    "=& \\nabla_\\theta KL(q(z) || p(z)) - \\mathbb{E}_{\\epsilon}[\\nabla_g \\log p(y|g_\\theta(\\epsilon)) \\times \\nabla_\\theta g_\\theta(\\epsilon)].\n",
    "\\end{align*}\n",
    "\n",
    "Then repeat using the same MCVI integration method to approximate the variational expectation. In practice, we can also use automatic differentiation to calculate the gradients.\n",
    "\n",
    "\n",
    "**Example: Variational Autoencoders (VAEs)**\n",
    "\n",
    "Model (Taken from https://lilianweng.github.io/lil-log/2018/08/12/from-autoencoder-to-beta-vae.html)\n",
    "\n",
    "![](autoencoder-architecture.png)\n",
    "\n",
    "**(1)**\n",
    "The decoder represents the likelihood $p(y|z)$, where $y$ is an image. In the upcoming example, we have\n",
    "\n",
    "$$\n",
    "\\log p(y|z) = \\log N(y; f_\\theta(z), I) \\equiv ||y - f_\\theta(z)||_2^2,\n",
    "$$\n",
    "\n",
    "the MSE loss.\n",
    "\n",
    "**(2)**\n",
    "The prior is $z\\sim \\mathcal{N}(0, I)$. \n",
    "\n",
    "**(3)**\n",
    "As you will see in many applications, they people only use 1 sample to calculate the variational expectation. i.e. taking $M=1$.\n",
    "\n",
    "**(4)**\n",
    "The variational distribution that we are going for is $$q(z|y) = N(g_\\phi(y)[0], g_\\phi(y)[1] I),$$\n",
    "where the variational distribution is parameterised by the encoder network.\n",
    "\n",
    "**(5)**\n",
    "We note that we can actually analytically compute the KL divergence as they are 2 Gaussians (proceed to Wikipedia for the formula...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples:  60000\n",
      "0 0.07181154936552048\n",
      "1 0.07108696550130844\n",
      "2 0.0702378898859024\n",
      "3 0.06724850833415985\n",
      "4 0.07055552303791046\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from https://github.com/ethanluoyc/pytorch-vae/blob/master/vae.py\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from six.moves import urllib\n",
    "opener = urllib.request.build_opener()\n",
    "opener.addheaders = [('User-agent', 'Mozilla/5.0')]\n",
    "urllib.request.install_opener(opener)\n",
    "\n",
    "class Normal(object):\n",
    "    def __init__(self, mu, sigma, log_sigma, v=None, r=None):\n",
    "        self.mu = mu\n",
    "        self.sigma = sigma  # either stdev diagonal itself, or stdev diagonal from decomposition\n",
    "        self.logsigma = log_sigma\n",
    "        dim = mu.get_shape()\n",
    "        if v is None:\n",
    "            v = torch.FloatTensor(*dim)\n",
    "        if r is None:\n",
    "            r = torch.FloatTensor(*dim)\n",
    "        self.v = v\n",
    "        self.r = r\n",
    "\n",
    "\n",
    "class Encoder(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        return F.relu(self.linear2(x))\n",
    "\n",
    "\n",
    "class Decoder(torch.nn.Module):\n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.linear1 = torch.nn.Linear(D_in, H)\n",
    "        self.linear2 = torch.nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.linear1(x))\n",
    "        return F.relu(self.linear2(x))\n",
    "\n",
    "\n",
    "class VAE(torch.nn.Module):\n",
    "    latent_dim = 8\n",
    "\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self._enc_mu = torch.nn.Linear(100, 8)\n",
    "        self._enc_log_sigma = torch.nn.Linear(100, 8)\n",
    "\n",
    "    def _sample_latent(self, h_enc):\n",
    "        \"\"\"\n",
    "        Return the latent normal sample z ~ N(mu, sigma^2)\n",
    "        \"\"\"\n",
    "        mu = self._enc_mu(h_enc)\n",
    "        log_sigma = self._enc_log_sigma(h_enc)\n",
    "        sigma = torch.exp(log_sigma)\n",
    "        std_z = torch.from_numpy(np.random.normal(0, 1, size=sigma.size())).float()\n",
    "\n",
    "        self.z_mean = mu\n",
    "        self.z_sigma = sigma\n",
    "\n",
    "        return mu + sigma * Variable(std_z, requires_grad=False)  # Reparameterization trick\n",
    "\n",
    "    def forward(self, state):\n",
    "        h_enc = self.encoder(state)\n",
    "        z = self._sample_latent(h_enc)\n",
    "        return self.decoder(z)\n",
    "\n",
    "\n",
    "def latent_loss(z_mean, z_stddev):\n",
    "    mean_sq = z_mean * z_mean\n",
    "    stddev_sq = z_stddev * z_stddev\n",
    "    return 0.5 * torch.mean(mean_sq + stddev_sq - torch.log(stddev_sq) - 1)\n",
    "\n",
    "\n",
    "\n",
    "input_dim = 28 * 28\n",
    "batch_size = 32\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()])\n",
    "mnist = torchvision.datasets.MNIST('./', download=True, transform=transform)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(mnist, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=2)\n",
    "\n",
    "print('Number of samples: ', len(mnist))\n",
    "\n",
    "encoder = Encoder(input_dim, 100, 100)\n",
    "decoder = Decoder(8, 100, input_dim)\n",
    "vae = VAE(encoder, decoder)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(vae.parameters(), lr=0.001)\n",
    "l = None\n",
    "for epoch in range(5):\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        inputs, classes = data\n",
    "        inputs, classes = Variable(inputs.resize_(batch_size, input_dim)), Variable(classes)\n",
    "        optimizer.zero_grad()\n",
    "        dec = vae(inputs)\n",
    "        ll = latent_loss(vae.z_mean, vae.z_sigma)\n",
    "        loss = criterion(dec, inputs) + ll\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        l = loss.item()\n",
    "    print(epoch, l)\n",
    "\n",
    "plt.imshow(vae(inputs).data[0].numpy().reshape(28, 28), cmap='gray')\n",
    "plt.show(block=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f81e3fe8b50>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(inputs[0].numpy().reshape(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalising Flows\n",
    "\n",
    "Using a \"nice\" class of diffeomorphisms, one can obtain diagonal Jacobians from the diffeomorphisms, we apply the change of variables formula:\n",
    "\\begin{align*}\n",
    "q(z_L) = q(z) \\prod_{l=1}^L |\\det(\\nabla_{z_{l-1}} T_l(z_{l-1}))|^{-1}\n",
    "\\end{align*}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
